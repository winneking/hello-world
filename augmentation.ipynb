{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "augmentation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/winneking/hello-world/blob/master/augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "WtDRc1Rolo87",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import math\n",
        "import h5py as h5py\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dKmCILQfm9FN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get -qq install -y graphviz && pip install -q pydot\n",
        "import pydot\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from IPython.display import Image\n",
        "\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input,Dense,Dropout,Flatten\n",
        "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "\n",
        "RATIO = 0.2\n",
        "\n",
        "NUM_DENSE = 5\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "ishape=48\n",
        "\n",
        "def tran_y(y):\n",
        "    y_ohe = np.zeros(NUM_DENSE)\n",
        "    y_ohe[y] = 1\n",
        "    return y_ohe\n",
        "  \n",
        "print('download vgg Model')\n",
        "\n",
        "model_vgg = VGG16(include_top = False, weights = 'imagenet',input_shape = (ishape,ishape, 3))\n",
        "\n",
        "for layer in model_vgg.layers:\n",
        "          layer.trainable = False\n",
        "model = Flatten()(model_vgg.output)\n",
        "model = Dense(4096, activation='relu',name='fc1')(model)\n",
        "model = Dense(4096, activation='relu',name='fc2')(model)\n",
        "model = Dropout(0.5)(model)\n",
        "model = Dense(NUM_DENSE,activation = 'softmax', name= 'prediction')(model)\n",
        "model_vgg_pretrain = Model(model_vgg.input, model, name = 'vgg16_pretrain')\n",
        "\n",
        "print('Model compile')\n",
        "\n",
        "sgd = SGD(lr = 0.05, decay = 1e-5)\n",
        "model_vgg_pretrain.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GU5kWddrG9BL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_model(model_vgg_pretrain, to_file=\"model.png\", show_shapes=True)\n",
        "Image('model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r_RA0lr8JPdb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('download Data')\n",
        "\n",
        "path='littleCBIR_none.npz'\n",
        "path = get_file(path,origin='https://github.com/jsxyhelu/DateSets/raw/master/littleCBIR_none.npz')\n",
        "f = np.load(path)\n",
        "X_train,y_train = f['X_train'], f['y_train']\n",
        "X_test,y_test = f['X_test'], f['y_test']\n",
        "\n",
        "X_train = [cv2.cvtColor(cv2.resize(i, (ishape,ishape)), cv2.COLOR_GRAY2BGR) for i in X_train]\n",
        "X_train = np.concatenate([arr[np.newaxis] for arr in X_train]).astype('float32')\n",
        "X_train /= 255.0\n",
        "\n",
        "X_test = [cv2.cvtColor(cv2.resize(i, (ishape,ishape)), cv2.COLOR_GRAY2BGR) for i in X_test]\n",
        "X_test= np.concatenate([arr[np.newaxis] for arr in X_test]).astype('float32')\n",
        "X_test /= 255.0\n",
        "\n",
        "y_train_ohe = np.array([tran_y(y_train[i]) for i in range(len(y_train))])\n",
        "y_test_ohe = np.array([tran_y(y_test[i]) for i in range(len(y_test))])\n",
        "y_train_ohe = y_train_ohe.astype('float32')\n",
        "y_test_ohe = y_test_ohe.astype('float32')\n",
        "\n",
        "\n",
        "#agumentation\n",
        "#Set building parameters\n",
        "img_generator = ImageDataGenerator(\n",
        "            featurewise_center=False, # set input mean to 0 over the dataset\n",
        "            samplewise_center=False,  # set each sample mean to 0\n",
        "            featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
        "            samplewise_std_normalization=False, #divide each input by its std\n",
        "            zca_whitening=False, # apply ZCA whitening\n",
        "            rotation_range=0,     # randomly rotate images in the range (degrees, 0 to 180)\n",
        "            width_shift_range=0.1, #randomly shift images horizontally (fraction of total width)\n",
        "            height_shift_range=0.1, #randomly shift images vertically (fraction of total height)\n",
        "            horizontal_flip=True, # randomly flip images\n",
        "            vertical_flip=False) #randomly flip images\n",
        "\n",
        "print('Training Model')\n",
        "#Training Model\n",
        "#TODOsteps_per_epoch =400\n",
        "img_generator.fit(X_train)\n",
        "log = model_vgg_pretrain.fit_generator(img_generator.flow(X_train,y_train_ohe,batch_size=128),steps_per_epoch=10,\n",
        " epochs=epochs,validation_data=(X_test,y_test_ohe),workers=4)\n",
        "score = model_vgg_pretrain.evaluate(X_test,y_test_ohe,verbose=0)\n",
        "\n",
        "#Display Print Result\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "#Plot loss and accc curve\n",
        "plt.figure('acc')\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(log.history['acc'],'r--',label='Training Accuracy')\n",
        "plt.plot(log.history['val_acc'],'r--',label='Validation Accuracy')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('Epochs')\n",
        "plt.axis([0,epochs,0.9,1])\n",
        "plt.figure('loss')\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(log.history['loss'],'b--',label='Training Loss')\n",
        "plt.plot(log.history['val_loss'],'b-',label='Validation Loss')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('Epochs')\n",
        "plt.axis([0,epochs,0,1])\n",
        "plt.show()\n",
        "\n",
        "model_vgg_pretrain.save('5type4cbirMODEL.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DbJo4QKHYqdn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Install the PyDrive wrapper &import libraties.\n",
        "#This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Create & upload a text file.\n",
        "uploaded = drive.CreateFile()\n",
        "uploaded.SetContentFile('5type4cbirMODEL.h5')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XlFHS3v_KStg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "#Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials =GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "#Download  by file name\n",
        "file_id ='1qjxAm_QiXdSqBmyIoPl3bfnyLNJxwKo9'\n",
        "downloaded =drive.CreateFile({'id':file_id})\n",
        "print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}