{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL4V5-1cifar10_Sequential.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/winneking/hello-world/blob/master/DL4V5_1cifar10_Sequential.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "i6Vqiv_ydksT",
        "colab_type": "code",
        "outputId": "089ccf66-15b9-4937-d9f5-5f6748db3443",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "yTmTLWW1dksZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PLamgoBRdksc",
        "colab_type": "code",
        "outputId": "d7f67ad9-5fcf-4c81-b549-a20e8c93d219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2kVWYoNudksf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "PN3ptx5Ydksh",
        "colab_type": "code",
        "outputId": "fc7619fc-9053-47e9-d990-cf8b2abc5e72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1346
        }
      },
      "cell_type": "code",
      "source": [
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),                       \n",
        "                        steps_per_epoch=x_train.shape[0]//batch_size,\n",
        "#                         steps_per_epoch=2000,\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/100\n",
            "1562/1562 [==============================] - 302s 193ms/step - loss: 1.8635 - acc: 0.3145 - val_loss: 1.6073 - val_acc: 0.4156\n",
            "Epoch 2/100\n",
            "1562/1562 [==============================] - 301s 193ms/step - loss: 1.5883 - acc: 0.4185 - val_loss: 1.4707 - val_acc: 0.4661\n",
            "Epoch 3/100\n",
            "1562/1562 [==============================] - 300s 192ms/step - loss: 1.4738 - acc: 0.4654 - val_loss: 1.2782 - val_acc: 0.5387\n",
            "Epoch 4/100\n",
            "1562/1562 [==============================] - 301s 193ms/step - loss: 1.3819 - acc: 0.5055 - val_loss: 1.2526 - val_acc: 0.5494\n",
            "Epoch 5/100\n",
            "1562/1562 [==============================] - 305s 195ms/step - loss: 1.3117 - acc: 0.5316 - val_loss: 1.1459 - val_acc: 0.5874\n",
            "Epoch 6/100\n",
            "1562/1562 [==============================] - 306s 196ms/step - loss: 1.2536 - acc: 0.5534 - val_loss: 1.2858 - val_acc: 0.5535\n",
            "Epoch 7/100\n",
            "1562/1562 [==============================] - 301s 193ms/step - loss: 1.2033 - acc: 0.5727 - val_loss: 1.1381 - val_acc: 0.5952\n",
            "Epoch 8/100\n",
            "1562/1562 [==============================] - 301s 193ms/step - loss: 1.1655 - acc: 0.5855 - val_loss: 1.0322 - val_acc: 0.6360\n",
            "Epoch 9/100\n",
            "1562/1562 [==============================] - 305s 195ms/step - loss: 1.1254 - acc: 0.6008 - val_loss: 0.9591 - val_acc: 0.6628\n",
            "Epoch 10/100\n",
            "1562/1562 [==============================] - 310s 198ms/step - loss: 1.0988 - acc: 0.6131 - val_loss: 0.9261 - val_acc: 0.6752\n",
            "Epoch 11/100\n",
            "1562/1562 [==============================] - 309s 198ms/step - loss: 1.0730 - acc: 0.6216 - val_loss: 1.1276 - val_acc: 0.6203\n",
            "Epoch 12/100\n",
            "1562/1562 [==============================] - 313s 200ms/step - loss: 1.0501 - acc: 0.6278 - val_loss: 0.9449 - val_acc: 0.6687\n",
            "Epoch 13/100\n",
            "1562/1562 [==============================] - 315s 202ms/step - loss: 1.0312 - acc: 0.6361 - val_loss: 0.9223 - val_acc: 0.6841\n",
            "Epoch 14/100\n",
            "1562/1562 [==============================] - 317s 203ms/step - loss: 1.0079 - acc: 0.6459 - val_loss: 0.8652 - val_acc: 0.7000\n",
            "Epoch 15/100\n",
            "1562/1562 [==============================] - 316s 202ms/step - loss: 0.9925 - acc: 0.6513 - val_loss: 0.8646 - val_acc: 0.7031\n",
            "Epoch 16/100\n",
            "1562/1562 [==============================] - 314s 201ms/step - loss: 0.9781 - acc: 0.6583 - val_loss: 0.8613 - val_acc: 0.7014\n",
            "Epoch 17/100\n",
            "1562/1562 [==============================] - 316s 202ms/step - loss: 0.9651 - acc: 0.6624 - val_loss: 0.8386 - val_acc: 0.7042\n",
            "Epoch 18/100\n",
            "1562/1562 [==============================] - 316s 202ms/step - loss: 0.9496 - acc: 0.6693 - val_loss: 0.8540 - val_acc: 0.7050\n",
            "Epoch 19/100\n",
            "1562/1562 [==============================] - 315s 202ms/step - loss: 0.9392 - acc: 0.6717 - val_loss: 0.8963 - val_acc: 0.6902\n",
            "Epoch 20/100\n",
            "1562/1562 [==============================] - 319s 204ms/step - loss: 0.9262 - acc: 0.6779 - val_loss: 0.8221 - val_acc: 0.7122\n",
            "Epoch 21/100\n",
            "1562/1562 [==============================] - 319s 204ms/step - loss: 0.9236 - acc: 0.6776 - val_loss: 0.8385 - val_acc: 0.7186\n",
            "Epoch 22/100\n",
            "1562/1562 [==============================] - 319s 204ms/step - loss: 0.9226 - acc: 0.6804 - val_loss: 0.8105 - val_acc: 0.7232\n",
            "Epoch 23/100\n",
            "1562/1562 [==============================] - 319s 204ms/step - loss: 0.9060 - acc: 0.6862 - val_loss: 0.7739 - val_acc: 0.7370\n",
            "Epoch 24/100\n",
            "1562/1562 [==============================] - 314s 201ms/step - loss: 0.9060 - acc: 0.6882 - val_loss: 0.8030 - val_acc: 0.7231\n",
            "Epoch 25/100\n",
            "1562/1562 [==============================] - 312s 200ms/step - loss: 0.8999 - acc: 0.6893 - val_loss: 0.8467 - val_acc: 0.7107\n",
            "Epoch 26/100\n",
            "1562/1562 [==============================] - 311s 199ms/step - loss: 0.8844 - acc: 0.6945 - val_loss: 0.7681 - val_acc: 0.7378\n",
            "Epoch 27/100\n",
            "1562/1562 [==============================] - 312s 200ms/step - loss: 0.8895 - acc: 0.6934 - val_loss: 0.7533 - val_acc: 0.7431\n",
            "Epoch 28/100\n",
            "1562/1562 [==============================] - 312s 199ms/step - loss: 0.8820 - acc: 0.6964 - val_loss: 0.8319 - val_acc: 0.7146\n",
            "Epoch 29/100\n",
            "1562/1562 [==============================] - 312s 200ms/step - loss: 0.8754 - acc: 0.6998 - val_loss: 0.7646 - val_acc: 0.7389\n",
            "Epoch 30/100\n",
            "1562/1562 [==============================] - 312s 200ms/step - loss: 0.8735 - acc: 0.7008 - val_loss: 0.7533 - val_acc: 0.7435\n",
            "Epoch 31/100\n",
            "1562/1562 [==============================] - 312s 200ms/step - loss: 0.8694 - acc: 0.7028 - val_loss: 0.7734 - val_acc: 0.7352\n",
            "Epoch 32/100\n",
            "1562/1562 [==============================] - 312s 199ms/step - loss: 0.8590 - acc: 0.7052 - val_loss: 0.7720 - val_acc: 0.7362\n",
            "Epoch 33/100\n",
            "1562/1562 [==============================] - 312s 200ms/step - loss: 0.8629 - acc: 0.7058 - val_loss: 0.7576 - val_acc: 0.7410\n",
            "Epoch 34/100\n",
            "1562/1562 [==============================] - 312s 200ms/step - loss: 0.8577 - acc: 0.7076 - val_loss: 0.7450 - val_acc: 0.7491\n",
            "Epoch 35/100\n",
            "1562/1562 [==============================] - 312s 200ms/step - loss: 0.8497 - acc: 0.7106 - val_loss: 0.7679 - val_acc: 0.7440\n",
            "Epoch 36/100\n",
            "1562/1562 [==============================] - 313s 201ms/step - loss: 0.8507 - acc: 0.7087 - val_loss: 0.7897 - val_acc: 0.7326\n",
            "Epoch 37/100\n",
            "1562/1562 [==============================] - 313s 200ms/step - loss: 0.8488 - acc: 0.7092 - val_loss: 0.7866 - val_acc: 0.7373\n",
            "Epoch 38/100\n",
            "1024/1562 [==================>...........] - ETA: 1:48 - loss: 0.8448 - acc: 0.7133Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6EUfTKZtdksl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}